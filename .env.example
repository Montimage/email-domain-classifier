# =============================================================================
# Email Domain Classifier - LLM Configuration
# =============================================================================
# Copy this file to .env and configure your settings.
# The .env file is gitignored and will not be committed.
# =============================================================================

# -----------------------------------------------------------------------------
# LLM Provider Configuration
# -----------------------------------------------------------------------------
# Provider selection: google, mistral, ollama, groq, openrouter
LLM_PROVIDER=ollama

# Model name (provider-specific). Leave empty to use provider default.
# Defaults:
#   - google: gemini-2.0-flash
#   - mistral: mistral-large-latest
#   - ollama: llama3.1:8b (recommended)
#   - groq: llama-3.3-70b-versatile
#   - openrouter: (specify model explicitly)
LLM_MODEL=llama3.1:8b

# Temperature for generation (0.0 = deterministic, 1.0 = creative)
# Recommended: 0.0 for classification tasks
LLM_TEMPERATURE=0.0

# Maximum response tokens
LLM_MAX_TOKENS=1024

# Request timeout in seconds
LLM_TIMEOUT=30

# Number of retries on failure
LLM_RETRY_COUNT=2

# -----------------------------------------------------------------------------
# Provider API Keys
# -----------------------------------------------------------------------------
# Only configure the key for your chosen provider

# Google (Gemini) - https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=

# Mistral AI - https://console.mistral.ai/api-keys/
MISTRAL_API_KEY=

# Groq - https://console.groq.com/keys
GROQ_API_KEY=

# OpenRouter - https://openrouter.ai/keys
OPENROUTER_API_KEY=

# -----------------------------------------------------------------------------
# Ollama Configuration (Local)
# -----------------------------------------------------------------------------
# No API key required for Ollama - it runs locally
# Install Ollama: https://ollama.ai/download

# Ollama base URL (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# -----------------------------------------------------------------------------
# Classification Method Weights
# -----------------------------------------------------------------------------
# Configure how much each classification method contributes to the final score.
# Weights are automatically normalized if they don't sum to 1.0.
#
# Default weights when LLM is enabled:
#   - Keyword Taxonomy: 35%
#   - Structural Template: 25%
#   - LLM: 40%

# Weight for LLM method (0.0 to 1.0)
LLM_WEIGHT=0.40

# Weight for keyword taxonomy method (0.0 to 1.0)
KEYWORD_WEIGHT=0.35

# Weight for structural template method (0.0 to 1.0)
STRUCTURAL_WEIGHT=0.25
