name: Quality Gates

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  quality-checks:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        pip install xenon radon pytest-cov
        
    - name: Coverage Threshold Check
      run: |
        pytest --cov=email_classifier --cov-report=xml --cov-fail-under=90 || true
        
    - name: Complexity Analysis
      run: |
        xenon --max-average=A --max-modules=B --max-absolute=C . || true
        
    - name: Performance Regression Test
      run: |
        python -m pytest tests/ --benchmark-only --benchmark-json=benchmark.json || true
        
    - name: Integration Tests
      run: |
        python -m pytest tests/integration/ -v || true
        
    - name: Quality Metrics Collection
      run: |
        echo "ðŸ“Š Quality Metrics Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Coverage metrics
        if [ -f "coverage.xml" ]; then
          echo "### ðŸ§ª Coverage Analysis" >> $GITHUB_STEP_SUMMARY
          COVERAGE=$(python -c "
import xml.etree.ElementTree as ET
tree = ET.parse('coverage.xml')
coverage_elem = tree.find('.//coverage')
line_rate = coverage_elem.get('line-rate', '0') if coverage_elem is not None else '0'
branch_rate = coverage_elem.get('branch-rate', '0') if coverage_elem is not None else '0'
print(f'{float(line_rate)*100:.1f}% line coverage')
print(f'{float(branch_rate)*100:.1f}% branch coverage')
" || echo "N/A")
          echo "- **Line Coverage**: $COVERAGE" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch Coverage**: $BRANCH_COVERAGE" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Complexity metrics
        echo "### ðŸ” Code Complexity" >> $GITHUB_STEP_SUMMARY
        if command -v xenon >/dev/null 2>&1; then
          echo "- **Average Complexity**: $(xenon --max-average=A --max-modules=B --max-absolute=C . | grep 'average complexity' | cut -d':' -f2 | tr -d ' ' || echo 'N/A')" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Performance metrics
        if [ -f "benchmark.json" ]; then
          echo "### âš¡ Performance Benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "- **Benchmark Results**: Available in artifacts" >> $GITHUB_STEP_SUMMARY
        fi
        
    - name: Upload quality artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: quality-metrics
        path: |
          coverage.xml
          htmlcov/
          benchmark.json
        retention-days: 30

  integration-tests:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.10", "3.11", "3.12"]
    needs: quality-checks
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        
    - name: Run integration tests
      run: |
        python -m pytest tests/ -v --integration-only || true
        
    - name: Test CLI functionality
      run: |
        pip install dist/*.whl || echo "No wheels found"
        email-classifier --version || echo "Version check failed"
        email-classifier --help || echo "Help check failed"
        email-classifier sample_emails.csv -o test-integration/ || echo "Integration test failed"

  performance-tests:
    runs-on: ubuntu-latest
    needs: quality-checks
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        pip install pytest-benchmark
        
    - name: Performance Benchmarking
      run: |
        python -m pytest tests/performance/ --benchmark-json=performance.json
        
    - name: Performance Analysis
      run: |
        echo "## âš¡ Performance Analysis" >> $GITHUB_STEP_SUMMARY
        if [ -f "performance.json" ]; then
          python -c "
import json
with open('performance.json', 'r') as f:
    data = json.load(f)
print('Performance metrics collected successfully')
" || echo "No performance data available"
        fi
        
    - name: Upload performance artifacts
      uses: actions/upload-artifact@v3
      with:
        name: performance-metrics
        path: performance.json
        retention-days: 30